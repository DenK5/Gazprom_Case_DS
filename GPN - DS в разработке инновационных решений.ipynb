{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6a58c4-c6ca-4b82-8e66-8a2825542ba6",
   "metadata": {},
   "source": [
    "# DS в разработке инновационных решений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81339ee8-10d8-4531-93f1-5d3c66dbec35",
   "metadata": {},
   "source": [
    "Решение **задачи регрессии**.\n",
    "\n",
    "Для анализа данных полученного DataFrame и дальнейшего построения модели ML, необходимо выполнить ряд следующих действий: \n",
    " - Загрузить DataFrame.\n",
    "\n",
    " - Проанализировать общую информацию. Посмотреть размерность данных, найти целевую переменную, посмотреть какие представлены типы столбцов, оценить среднее и минимальное значение по столбцам, оценить количество пропущенных значений в каждом столбце, проанализировать распределение значений по каждому столбцу, посмотреть на наличие выбросов в данных, найти при необходимости их количество, проанализировать показатели корреляции между параметрами, создать при необходимости гиперпараметры, удалить при необходимости лишние столбцы (обосновав это).\n",
    "\n",
    " - При необходимости произести шкалирование данных, при наличии выбросов в данных, разных масштабов среди столбцов, или при использовании методов ML чувствительных к масштабу данных (например, линейная регрессия, метод  ближайших соседей).\n",
    "\n",
    " - Если необходимо, произвести трансформирование данных, при наличии категориальных параметров.\n",
    "\n",
    " - Произвести подготовку данных, создать датасет с фичами и выделить целевую переменную (y).\n",
    "\n",
    " - Выбрать методы Ml и метрику ошибки.\n",
    "\n",
    " - Проанализировать результативность методов ML и выбрать наилучший вариант решения задачи.\n",
    "\n",
    " - Сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdabdef8-4456-402e-b092-4e5c6aceb6fa",
   "metadata": {},
   "source": [
    "# Раздел 1: Анализ и обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce18f62-27fa-4a09-808b-9eb2c50ae4e0",
   "metadata": {},
   "source": [
    "- Создадим блок, в который будем добавлять импорт всех необходимых библиотек. В процессе решения, будем добавлять их именно сюда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f76be48-3605-419b-b686-c13b2285e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем библиотеки\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a8c1ff-0baa-4465-8d51-862686010f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим DataFtame\n",
    "df = pd.read_csv(\"C:/Users/kdm01/OneDrive/Рабочий стол/DataSets/GPN - разр иновац реш/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e35722-4970-4eb2-b67f-325d297ec597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем первые пять строк нашего DataFrame.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036ed22-d490-4607-9f15-8c709f0f43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим общую информацию о DataFrame.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ced74-e654-4b03-8332-1b224106a8cb",
   "metadata": {},
   "source": [
    "Анализируя код ниже, замечаем, что:\n",
    "- Один единственный параметр имеет единственный тип \"int64\"\n",
    "- Только два параметра имеют тип \"object\".\n",
    "**Оценим их позже.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874eccdc-c069-4f81-82d3-a3a1282d4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим общую информацию о DataFrame.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bf628-5680-44bc-aaa4-7a74ca31367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Еще раз оценим количесво пропущенных значений. Пропущенных значений в DataFrame нет.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a083d94-7d83-46c8-be1a-87d28fa97d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим уникальные значения по столбцу \"Температура вдоха Истока\" и \"Давление вдоха Истока\", поймем, что они имееют только по одному уникальному значению,\n",
    "# то есть, эти параметры константы для входа в систему.\n",
    "\n",
    "# Оценим уникальные значения по столбцу \"Температура выдоха Истока\" и \"Древний Ветер\", это два единственных столбца имеющих тип \"object\".\n",
    "uniq1 = df['Температура вдоха Истока'].unique()\n",
    "uniq2 = df['Давление вдоха Истока'].unique()\n",
    "\n",
    "uniq3 = df['Температура выдоха Истока'].unique()\n",
    "uniq4 = df['Древний Ветер'].unique()\n",
    "\n",
    "\n",
    "print(f\"Уникальные значения для столбца: 'Температура вдоха Истока' = {uniq1}\")\n",
    "print()\n",
    "print(f\"Уникальные значения для столбца: 'Давление вдоха Истока' = {uniq2}\")\n",
    "print()\n",
    "print(f\"Уникальные значения для столбца: 'Температура выдоха Истока' = {uniq3}\")\n",
    "print()\n",
    "print(f\"Уникальные значения для столбца: 'Древний Ветер' = {uniq4}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d44d493-3e89-48b3-9043-014da31c8109",
   "metadata": {},
   "source": [
    "- В столбцах \"Температура выдоха Истока\" и \"Древний Ветер\" видим такие значения как, **\"Исток не вернул выдох\"** и **\"Древний Ветер развеялся\"**, соответсвенно.\n",
    "- Из истории вселенной Ведьмака понимаем, что эти значения вляются Температрурой воздуха в цельсиях и Энергией. Эти параметры регестрируюстся на выходе из системы.\n",
    "- **\"Исток не вернул выдох\"** - предположу, что это значит, что приборы не смогли зарагестрировать температуру воздуха (возможно, вследствии отстуствия энергии, проблем с оборудованиям, нестабильностью источника или потерянных данных).\n",
    "- **\"Древний Ветер развеялся\"** - предположу, что значение давления было минимальным и регестрация была невозможна (сведетельсвтует об отсутствии потока, энергии и соответственно давления.)\n",
    "- Также видим, что явления нерегестрации температуры и давления **происходят параллельно** (проверим это ниже), что действительно может сведетельствать об отсутвии потока. Ведь вероятность поломки термометра и бараметра одновременно и строго параллельно, крайне мала !!!\n",
    "- Будем считать эти параметры как **пропущенные значения**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310836d7-7edd-479e-b006-d67d0cff90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим, совпадает ли количество явлений \"нерегестрации\" температуры и давления. Найдем количество нерегестрации температуры и давления.\n",
    "\n",
    "shape1 = df[df['Температура выдоха Истока'] == 'Исток не вернул выдох'].shape[0]\n",
    "shape2 = df[df['Древний Ветер'] == 'Древний Ветер развеялся'].shape[0]\n",
    "\n",
    "print(f'Кольчество строк, с незафиксированной температурой: {shape1}')\n",
    "print(f'Кольчество строк, с незафиксированным давлением: {shape2}')\n",
    "\n",
    "if shape1 == shape2:\n",
    "    print('Количество явлений совпадает')\n",
    "else:\n",
    "    print('Разное количество явлений')\n",
    "\n",
    "# Но, мы не можем быть точно уверены, что явления происходят параллельно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165bd80-c17d-4ef9-805d-53fd08bb4149",
   "metadata": {},
   "source": [
    "- Мы поняли, что количество явлений одинаково. Осталось оценить, что эти явления происходят **параллельно**!\n",
    "\n",
    "- Если явления происходят строго параллельно, это скажет нам, об их прямой зависимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e36d9a-e8d0-4b9b-9756-c47775a9d346",
   "metadata": {},
   "source": [
    "Создан DataFrame объединяющий эти явления ('Исток не вернул выдох' и 'Древний Ветер развеялся'). Посчитаем их количество. \n",
    "\n",
    "Если количество строк нового DataFrame, который объединяет эти два явления, **сповпадает** с количеством каждого явления (9547) с предыдущего шага, значит, что явления нерегестрации температуры и давления происходят **строго параллельно**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddaae1f-d1b2-4191-9b34-227261d6ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Так же оценим, что эти явления происходят параллельно.\n",
    "\n",
    "parall = df[(df['Температура выдоха Истока'] == 'Исток не вернул выдох') & (df['Древний Ветер'] == 'Древний Ветер развеялся')].shape[0]\n",
    "print(parall)\n",
    "\n",
    "if parall == shape1 == shape2:\n",
    "    print('Явления нерегестрации температуры и давления происходят одновременно и параллельно!')\n",
    "else:\n",
    "    print('Не параллельно')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1561ef8-5d7b-4ab7-a217-9b2f6a5f3dc0",
   "metadata": {},
   "source": [
    "Выяснено, что явления нерегестрации температуры и давления происходят одновременно, соответственно между ними прямая взаимосвязь."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd026f96-9914-42cd-b5f2-b7058d00268b",
   "metadata": {},
   "source": [
    "- Так как ранее было выяснено, что параметры \"Температура вдоха Истока\" и \"Давление вдоха Истока\" имеют по одному уникальному значению, **исключим** их из DataFrame, поскольку **константы** никакой информации для моделей ML не несут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be93c7-8f51-4815-9d30-ffda73cf3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим из нашего DataFrame константные значения, поскольку никой информации для будущей модели они не несут.\n",
    "df = df.drop(columns=[\"Температура вдоха Истока\", \"Давление вдоха Истока\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6c63f-d851-4c6e-b59f-f46e21bca4e0",
   "metadata": {},
   "source": [
    "- Далее работа с новым DataFrame - **df_new**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55bc497-e31d-4c65-b900-50b0a2316f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменим явления 'Исток не вернул выдох' и 'Древний Ветер развеялся' на NaN, обозначая их как пропущенное значение.\n",
    "\n",
    "df_new = df.copy()\n",
    "df_new['Температура выдоха Истока'] = df_new['Температура выдоха Истока'].replace('Исток не вернул выдох', np.nan)\n",
    "df_new['Древний Ветер'] = df_new['Древний Ветер'].replace('Древний Ветер развеялся', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f9cf1-e9f9-41bd-82b6-ffc0c1d8ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим что получилось\n",
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f422-5ecf-40c5-aa05-badc800de875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим количество пропущенных значений\n",
    "df_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e80ee9-4366-4a42-b668-e9e9449b92e9",
   "metadata": {},
   "source": [
    "- Столбцы \"Температура выдоха Истока\" и \"Древний Ветер\" имеют по 9547 пропущенных значения.\n",
    "\n",
    "- Это **80% пропущенных значений** всех данных по столбцу (9547/11934 = 0.7999).\n",
    "\n",
    "- Оценим значимость этих столбцов позже, запомнив о таком большом количестве пропусков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a0d30-b295-4e9e-b40a-34ba3f83fd3d",
   "metadata": {},
   "source": [
    "- Необходимо проверить признаки DataFrame на корреляцию. Для этого построим корреляционную матрицу и проанализируем результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3133d7d-b6c5-4d43-842d-6714fe350fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим корреляционную матрицу для всех параметров в нашем DataFrame\n",
    "correlation_matrix = df_new.corr()\n",
    "\n",
    "plt.figure(figsize=(11, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a7e98-b5d6-4c5b-9233-fcbf35a602f0",
   "metadata": {},
   "source": [
    "- Корреляция почти между всеми параметрами очень большая (0.88+).\n",
    "\n",
    "- Практически все параметры очень слабо коррелируют с целевой переменной, \"Гармония Бессмертия\".\n",
    "\n",
    "- Видно, что очень сильное влияние почти всех столбов друг на друга. И очень слабое влияние на целевой столбец."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51adc0e-4554-4656-a0cd-add3ec1202f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим что корреляция между 'Сила Левого Потока', 'Сила Правого Потока' и 'Приток Силы Потока' равна 1\n",
    "# Создадим новую переменную, для более полной картины суммарной силы всех потоков\n",
    "df_new['Полная мощность потоков'] = df_new['Сила Левого Потока'] + df_new['Сила Правого Потока'] + df_new['Приток Силы Потока']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a84b8-a88e-4458-992d-b4e3d08b09da",
   "metadata": {},
   "source": [
    "- Создадим новый параметр \"Полная мощность потоков\".\n",
    "\n",
    "- Оценим корреляцию других параметров с параметром \"Полная мощность потоков\" - (она очень высокая)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc57e2c-9ade-4a09-bd8d-bc0e87ec06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим корреляцию\n",
    "\n",
    "correlation_matrix = df_new.corr()\n",
    "\n",
    "plt.figure(figsize=(11, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ed0d3-16bb-499f-8910-4df343209b0a",
   "metadata": {},
   "source": [
    "#### Добавление гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b21c7e-6398-437b-a357-50c5c4d12843",
   "metadata": {},
   "source": [
    "- Добавим в DataFrame большую часть новых столбцов, исходя из информации, содержащийся в разделе \"Дополнительные рекомендации по работе с данными\". Создание и добавление гиперпараметров, необходимо, для более четкого понимания картины взаимосвязи данных.\n",
    "\n",
    "- Проанализируем корреляцию остальных параметров и новых, только что созданных.\n",
    "\n",
    "- Проанализируем кореляцию новых параметров с целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a8309-ba06-47e9-ad73-8f74f8b6d41e",
   "metadata": {},
   "source": [
    "```\n",
    "Почему добавлены все гиперпараметры ?\n",
    "\n",
    "- При добавлении всех гиперпараметров, мы однозначно не сделаем себе хуже. Чем больше параметров, тем больше данных, а это хорошо как для нас, так и для методов ML.\n",
    "\n",
    "- При наличии большего количества данных, мы сможем лучше понять их взаимосвязь друг с другом, более обьективно оценить корреляцию параметров, их важность и значимость для моделей ML. Возможно, какой-то гиперпараметр будет чрезвычайно важен для моделей ML.\n",
    "\n",
    "- Добавляем все гиперпараметры, анализируем их и при необходимости удаляем.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6664e-0158-43b3-b283-7d1dde70e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление гиперпараметров.\n",
    "df_new['Общая мощность ядра'] = df_new['Ритм магического ядра'] * df_new['Приток Силы Потока']\n",
    "df_new['Общее давление'] = df_new['Приток давления Выдоха Истока'] + df_new['Давление выдоха Истока']\n",
    "df_new['Магическая производительность'] = df_new['Скорость перехода через портал'] / df_new['Эмульсия Истока']\n",
    "df_new['Эффективность ядра'] = df_new['Общая мощность ядра'] / df_new['Эмульсия Истока']\n",
    "df_new['Степень износа'] = df_new['Дыхание Истока'] / df_new['Гармония Бессмертия']\n",
    "df_new['Разница стабильности'] = abs(df_new['Дыхание Истока'] - df_new['Гармония Бессмертия'])\n",
    "df_new['Баланс угасания'] = (df_new['Дыхание Истока'] - df_new['Гармония Бессмертия']) / df_new['Скорость перехода через портал']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4687a4-426d-47ea-a7e0-b6990acd2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим ОБЩУЮ корреляцию после добавления всех параметров.\n",
    "correlation_matrix = df_new.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar=False)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c5b20-7540-4248-9fff-622e7fa196c6",
   "metadata": {},
   "source": [
    "# Решение задачи выполнено двумя вариантами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ab194-ed84-4aae-b0e2-c7ff08c53308",
   "metadata": {},
   "source": [
    "- При решении задачи тестировались разные гипотезы. Данная задача регресии решена двумя абсолютно разными вариантами.\n",
    "\n",
    "- В конце каждого варианта решения есть свой промежуточный вывод.\n",
    "\n",
    "- В конце задачи подведен общий итог, в котором выбирается, как метод решения, так и модель ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b16bc-4c04-43f5-9204-20b30ad3a5b7",
   "metadata": {},
   "source": [
    "# Вариант №1 - строим модель без удаления коррелирующих столбцов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614f11c-f4d9-45d2-b889-eb87896d1a33",
   "metadata": {},
   "source": [
    "- Для начала протестируем первую стратегию:\n",
    "  \n",
    "    1. Не будем сразу удалять все сильно коррелирующие столбцы. Т.к мы не можем в полной мере понимать их значимость для моделей ML. Через матрицу корреляции, мы видим только взаимосвязь признаков друг с другом. Но, удалив сильно коррелирующий столбец, мы можем потерять **значимый признак** для решения задачи регресии и получить более слабую модель.\n",
    " \n",
    "    2. Вместо удаления коррелирующих столбцов, загрузим все признаки и обучим на них модель ML. Далее оценим значимость признаков для нашей модели, выберем для себя \"отсечку\" значимости признаков и удалим все признаки ниже нашего порогового значения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba12f67-e00e-4603-8e3a-4d877d5fa0bd",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8eaa1c-e0b0-4bbc-87fb-cb79da95293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обозначим целевую переменную как y и остальные параметры как X\n",
    "X = df_new.drop(['Гармония Бессмертия'], axis = 1)\n",
    "y = df_new['Гармония Бессмертия']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8428a-4210-42fb-95d8-e1f2da2ad031",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4d700-fdfe-4633-82fb-183e89697f3a",
   "metadata": {},
   "source": [
    "## Масштабирование данных: StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634c0e1-addc-4cea-ab68-3319348a4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6e3cd-e0ec-4f7e-85fc-1f5d73177cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем данные на тестовую и тренировочную выборку. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state=230) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d48e62-ba7e-4086-8226-42b5e76a5dfc",
   "metadata": {},
   "source": [
    "- test_size = 0.40, задаем размерность тестовой выборки. Это значит, что весь DataFrame разобьется в соотношении 60 к 40, на 60% модель обучается и на 40% тестируется.\n",
    "- random_state = 250 - это фиксированное перемешивание данных в DataFrame. Меняя random_state, мы показываем модели данные, которые она раньше не видела. Это предотвращает \"подстраивание\" модели под тестовую выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e93bb9-17f8-420c-b086-645d3e3a3ebb",
   "metadata": {},
   "source": [
    "```\n",
    "Изначально решение было выполнено вариантом решения №2. В данном варианте решения №1 я выбрал 3 самых сильных метода, исходя из опыта решения варианта №2.\n",
    "\n",
    "На основе метода Extreme Gradient Boosting, Random Forest и CatBoost воспользуюсь feature_importances_ и .get_feature_importance(), и проанализирую важность всех фичей в DataFrame.\n",
    "\n",
    "В варианте решения № 1, протетирую 3 метода ML:\n",
    "\n",
    "    1. Extreme Gradient Boosting.\n",
    "    2. Метод ближайших соседей.\n",
    "    3. Random Forest.\n",
    "\n",
    "После удаления малозначимых параметров проанализируем, как справятся эти методы с большим количеством сильно коррелирующих параметров.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600c0a3-4ac1-4160-85f7-388ab78f3636",
   "metadata": {},
   "source": [
    "## Метод: Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b24448-95e3-4759-9013-449b80887e85",
   "metadata": {},
   "source": [
    "- Обучим модель на большом количестве сильно коррелирующих данных.\n",
    "\n",
    "- Метод Extreme Gradient Boosting имеет высокую скорость обучения, относительно других выбранных методов. Поэтому, для этой задачи был выбран именно он.\n",
    "\n",
    "- После обучения модели, воспользуемся feature_importances_ для выявления значимости фичей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd630c1-07fb-4123-8e61-2a1139e6e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='mae')\n",
    "\n",
    "# Запишем необходимые нам параметры для дальнейшего перебора.\n",
    "param_xgb = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'learning_rate': [0.1, 0.2],  \n",
    "    'max_depth': [3, 5, 10],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]    \n",
    "}\n",
    "\n",
    "# Сделаем перебор заданных выше параметров, при этом разделив выборку данных на 5 частей.\n",
    "grid_search__xgb = GridSearchCV(xgb_regressor, param_xgb, cv=5)\n",
    "\n",
    "# Обучим модель на тренировочных данных\n",
    "grid_search__xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2cc6d3-1a65-4587-83e7-e6efb3ed7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим лучшие параметры, дающие максимальный прирост Information gain\n",
    "grid_search__xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f8ac1-f561-43a0-aabf-97b351133f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним эти параметры в новую переменную, чтобы далее с ними работать\n",
    "best_gs_xgb = grid_search__xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e4608-aecd-43a4-b1c2-dbfecfae09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_gs_xgb.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_gs_xgb.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedb895-5370-4b28-a472-44f9a7d160d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся feature_importances_ чтобы получить array важности всех фичей в данных\n",
    "# Данный вывод array нам ничего не говорит, необходимо преобразовать его в более читаемый вид.\n",
    "best_gs_xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e43a38-11e2-463e-bcee-89ba969a638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним в отдельную переменную, чтобы создать DataFrame (для читаемости)\n",
    "feature_importances = best_gs_xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501cce5-68e1-42d6-a702-0349f6cb2248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим DataFrame для наглядности.\n",
    "# Смотрим важность фичей в нашем DataFrame\n",
    "feature_importances_df = pd.DataFrame({'features': feature_names,\n",
    "                                       'feature_importances': feature_importances})\n",
    "feature_importances_df.sort_values('feature_importances', ascending=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa93ac9-180d-445f-b63d-85b201c8a24a",
   "metadata": {},
   "source": [
    "- В DataFrame выше, показаны все фичи по **убыванию их важности**.\n",
    "- Но, основная проблема заключается в том, что при изменении параметра **random_state**, в команде разбиения датасета на тестовую и тренировочную выборки, важность фичей и их место в \"градации по важности\", будет меняться.\n",
    "  \n",
    "```\n",
    "- Почему это так происходит? Это связано с тем, что меняя random_state, набор данных буквально перемешивается. И метод ML, фактически получает на вход новые данные. Далее, в новых данных он находит новые значения и новые вариации построения дерева решений (Дерево решений, т.к. метод feature_importances_ использовался в методе exgBoosting, который в свою очередь работает на основе алгоритмов деревьев решений). Находя новые вариации построения деревьев решений, могут изменяться сплиты разных параметров, изменяется прирост Information gain, следовательео может меняться и значимость различных столбцов.\n",
    "```\n",
    "\n",
    "- То есть, если при random_state=250, важность параметра \"Эффективность ядра\" = 0.000000, то при random_state=350, важность этого параметра будет уже 0.000876. То есть, **минимальный вклад этот параметр уже вносить будет**.\n",
    "- Чтобы решить этот вопрос, и не удалить фичи которые сейчас нам кажутся **бесполезны**, а потенциально оказывается, что они могут **принести пользу**, напишем цикл, прогоняющий фичи несколько раз и выведем среднее значение и медиану для разных комбинаций фичей, при разном random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a132716-cf97-44a4-9faf-b6eb3f99864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 4\n",
    "importances_list = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=250 + i)\n",
    "    \n",
    "    xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='mae')\n",
    "    grid_search_xgb = GridSearchCV(xgb_regressor, param_xgb, cv=5, n_jobs=-1)\n",
    "    \n",
    "    grid_search_xgb.fit(X_train, y_train)\n",
    "    best_model = grid_search_xgb.best_estimator_\n",
    "    \n",
    "    feature_importances = best_model.feature_importances_\n",
    "    importances_list.append(feature_importances)\n",
    "\n",
    "importances_df = pd.DataFrame(importances_list, columns=feature_names)\n",
    "\n",
    "importances_summary_xg = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'mean_importance': importances_df.mean(),\n",
    "    'median_importance': importances_df.median()})\n",
    "\n",
    "importances_summary_xg.sort_values('mean_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b037c74-91ee-4ae3-b2e0-61eaf72d3bf9",
   "metadata": {},
   "source": [
    "**Для обьективности** проведем такой же тест для метода Random Forest. \n",
    "\n",
    "```\n",
    "Оценим какие фичи важны для метода RF и сравним их с методом Extreme Gradient Boosting\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb3948-3bbe-4b24-a106-3907ed522489",
   "metadata": {},
   "source": [
    "- Проанализируем важность фичей и для модели Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643152b6-79ae-4836-a6d7-13b2c7742325",
   "metadata": {},
   "source": [
    "## Метод: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb783e-9192-467f-8691-bf4ced62a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_forest = RandomForestRegressor()\n",
    "\n",
    "# Распишем параметры для теста через GridSearchCV.\n",
    "parametrs_fr = {'max_depth':[3, 5, 10],\n",
    "              'n_estimators':[10, 100, 200],\n",
    "              'max_features':[1, 3, 5, 7]}\n",
    "\n",
    "# Прогоним модель RF, тестируя вышеперечисленные параметры, разделив выборку на 5 частей.\n",
    "grid_search_reg_forest3 = GridSearchCV(reg_forest, parametrs_fr, cv = 5)\n",
    "\n",
    "# Обучим на тренировочных данных.\n",
    "grid_search_reg_forest3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbacd8e1-53a9-4da5-9977-2e357f3fb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на лучшие параметры.\n",
    "grid_search_reg_forest3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7c8f0-09ed-4c46-b51d-243acd594232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим коэффициент детерминации - точность предсказанных значений.\n",
    "best_rf_reg3 = grid_search_reg_forest3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483e86a-16e7-41e8-b490-069918cc5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_rf_reg3.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_rf_reg3.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931170a-176d-49d0-a704-a06c43dce932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся feature_importances_ для выявления самых значимых фичей для метода RF.\n",
    "best_rf_reg3.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beba572-98b8-431b-a089-c2e094cecc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances2 = best_rf_reg3.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71532063-c323-4a3d-b152-a96b81f00acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним для визуализации в DataFrame\n",
    "feature_importances_df2 = pd.DataFrame({'features': feature_names,\n",
    "                                       'feature_importances': feature_importances2})\n",
    "feature_importances_df2.sort_values('feature_importances', ascending=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c6b9be-0099-47d7-b657-089a425d364a",
   "metadata": {},
   "source": [
    "- Описав выше проблему random_state, для обьективности важности фичей, воспользуемся циклом, прогнав фичи через изменяющийся random_state и сохраним их среднее и медианное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0a351-fde7-4978-a8bd-34a984b7954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 3\n",
    "importances_list = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    # Разделение данных с разными random_state\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=250 + i)\n",
    "    \n",
    "    reg_forest = RandomForestRegressor()\n",
    "    grid_search_reg_forest3 = GridSearchCV(reg_forest, parametrs_fr, cv = 5)\n",
    "    \n",
    "    grid_search_reg_forest3.fit(X_train, y_train)\n",
    "    best_rf_reg3 = grid_search_reg_forest3.best_estimator_\n",
    "    \n",
    "    feature_importances = best_rf_reg3.feature_importances_\n",
    "    importances_list.append(feature_importances)\n",
    "\n",
    "importances_df = pd.DataFrame(importances_list, columns=feature_names)\n",
    "\n",
    "# Рассчитаем среднее и медиану важности для каждой фичи\n",
    "importances_summary_rf = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'mean_importance': importances_df.mean(),\n",
    "    'median_importance': importances_df.median()})\n",
    "\n",
    "# Выведем отсортированный DataFrame, по среднему значению\n",
    "importances_summary_rf.sort_values('mean_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c6e4b-06b2-4f50-afed-911b8d60b053",
   "metadata": {},
   "source": [
    "Представленные выше фичи - это отсортированный DataFrame по **важности** столбцов нашего DataFrame для метода **Random Forest**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba30c42-99c6-4b61-9036-ab9ec54b01b0",
   "metadata": {},
   "source": [
    "## Метод: CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb5094-16fe-4b9e-9a18-a27ac90dfb3d",
   "metadata": {},
   "source": [
    "- Так же воспользуемся библиотекой ML разработанной Яндексом - CatBoost.\n",
    "\n",
    "- Этот алгоритм машиного обучения имеет метод - .get_feature_importance().\n",
    "\n",
    "- Данный метод чуть более гибкий в отличии от предыдущего .feature_importances_ :\n",
    "\n",
    "    - CatBoost автоматически обрабатывает категориальные признаки, что делает его более точным на реальных данных.\n",
    "    - CatBoost более устойчив к случайным вариациям в данных по сравнению с XGBoost, т.к он использует метод \"Ordered Boosting\". Это позволяет получить более стабильную оценку важности признаков.\n",
    "    - CatBoost менее подвержен переобучению.\n",
    "\n",
    "- Так же, вывод важности параметров через метод .get_feature_importance() более нагляден, т.к в сумме все параметра образуют значение 100 и сразу видно, какой вклад вносит каждый столбец в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d639e8a-8469-4c78-b2af-a37a3b698826",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_regressor = CatBoostRegressor(loss_function='MAE', silent=True)\n",
    "\n",
    "param_catboost = {\n",
    "    'iterations': [150, 300],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'depth': [5, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "grid_search_catboost = GridSearchCV(catboost_regressor, param_catboost, cv=3)\n",
    "\n",
    "grid_search_catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132fc914-d319-4961-8af6-1f4d6e3d31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_catboost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c3c8e-b1e3-4692-bcc3-0cc6ad2f0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gs_catboost = grid_search_catboost.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3d9b6-b94d-4983-91c0-8bdef81c96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_gs_catboost.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_gs_catboost.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deed0e0-4c1d-4b8f-868d-f1fe4772ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем важность признаков с помощью метода get_feature_importance\n",
    "feature_importances = best_gs_catboost.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80e253-c376-43f1-8e19-ebe53d7005ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame для удобного представления результатов\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'features': feature_names, \n",
    "    'feature_importances': feature_importances\n",
    "})\n",
    "\n",
    "feature_importances_df.sort_values(by='feature_importances', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dab949-ac35-4487-b251-e6e1f631df9d",
   "metadata": {},
   "source": [
    "- Видем выше DataFrame - градация от самых важных признаков к менее важным, по методу CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423707e-405b-4b86-88a4-23869b1adc9a",
   "metadata": {},
   "source": [
    "```\n",
    "Проанализировав 3 DataFrame, выводящие градации всех столбов по их важности и значимости, для методов: Extreme Gradient Boosting, RandomForest и CatBoost, заметим, что верхний пласт самых значимых параметров, не меняется от метода в методу!\n",
    "```\n",
    "**Самые важные параметры**, их 4: Дыхание Истока, Разница стабильности, Степень износа, Баланс угасания.\t\n",
    "```\n",
    "Эти параметры однозначно должны быть в DataFrame.\n",
    "\n",
    "Остальные параметры, тоже играют некоторую роль, но их значимость существенно ниже, особенно у самых последних.\n",
    "\n",
    "Параметры вносящие минимальный вклад или не вносящие вовсе, от таких параметров лучше избавляться. Так, мы упростим сам DataFrame и улучшим обобщающую способность модели.\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33950215-7998-4bb7-a0a1-3f9ec68293c9",
   "metadata": {},
   "source": [
    "### Построим график для визуализации важности параметров "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a42de2-dfa5-4a20-a1b6-b932aa8b0f62",
   "metadata": {},
   "source": [
    "- Сохраним в отдельные переменные итоговый, отсортированный по среднему значению список важности столбцов, для двух моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c011d-24c6-4d57-943c-3efe2aebeac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_summary_xgb = importances_summary_xg.sort_values('mean_importance', ascending=False).reset_index(drop=True)\n",
    "importances_summary_rrf = importances_summary_rf.rename(columns={'mean_importance': 'RF_mean_importance'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811b0b7-eddf-4368-a49b-b938fa847b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим общую таблицу, где будут важности признаков обоих методов\n",
    "importances_summary_rf = importances_summary_rf.rename(columns={'mean_importance': 'RF_mean_importance'})\n",
    "importances_summary_xgb = importances_summary_xgb.rename(columns={'mean_importance': 'XGB_mean_importance'})\n",
    "\n",
    "# Объединим таблицы по признакам\n",
    "combined_importances = pd.merge(importances_summary_rf[['feature', 'RF_mean_importance']],\n",
    "                                importances_summary_xgb[['feature', 'XGB_mean_importance']],\n",
    "                                on='feature')\n",
    "\n",
    "# Построим график\n",
    "plt.figure(figsize=(10, 8))\n",
    "indices = np.arange(len(combined_importances))\n",
    "\n",
    "plt.barh(indices - 0.2, combined_importances['RF_mean_importance'], height=0.4, label=\"Random Forest\", color='skyblue')\n",
    "plt.barh(indices + 0.2, combined_importances['XGB_mean_importance'], height=0.4, label=\"XGBoost\", color='salmon')\n",
    "\n",
    "plt.yticks(indices, combined_importances['feature'])\n",
    "plt.xlabel('mean_importance')\n",
    "plt.title('Сравнение важности признаков: Random Forest vs XGBoost')\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22695c10-cee4-4805-9b54-5e086725d5ff",
   "metadata": {},
   "source": [
    "- На данном графике сразу можно заметить 4 самых важных столбца, как для метода XGBoost так и для Random Forest.\n",
    "\n",
    "- Остальные же столбцы, могут быть менее важны для одной модели и чуть более важны для другой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58e5a9-ec1b-4e1a-a9ec-b2e0ab25a9ea",
   "metadata": {},
   "source": [
    "### Удаление фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724f514-da7d-40b8-b643-c4141b79711d",
   "metadata": {},
   "source": [
    "- Оценим важность фичей для трех методов ML:\n",
    "  1. Метод: Extreme Gradient Boosting\n",
    "  2. Метод: Random Forest\n",
    "  3. Метод: CatBoost\n",
    "\n",
    "Проанализируем три DataFrame с отсортированными, средними значениями важных фичей. Проанализируем график. \n",
    "- Выберем отсечку и удалим столбцы с оценкой важности, ниже заданной отсечки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830c1bc-18fa-45a0-873a-f36b56e8f927",
   "metadata": {},
   "source": [
    "Возьмем для нашей \"отсечки\", значения **не ниже 0.0003** по среднему значению у модели XGBoost. **Не будем убирать** параметр **'Общее давление'**, хотя он имеет значение важности 0.000170 для метода Extreme Gradient Boosting, но он так же входит в топ-8 для метода Random Forest и в топ-7 для CatBoost, что достаточно неплохо.\n",
    "\n",
    "- Удалим все фичи ниже этого значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45bb78-bfd7-424d-9c60-1cd07f894027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем новый DataFrame, с самыми значимыми фичами в новую переменную, удаляя все фичи со заченями ниже 0.0003 по mean. \n",
    "df_new_two = df_new.drop(['Температура выдоха Истока', 'Полная мощность потоков', \n",
    "                          'Поток Энергий', 'Вектор Мощи', 'Скорость перехода через портал', 'Приток давления Выдоха Истока',\n",
    "                          'Сила Правого Потока', 'Сила Левого Потока', 'Древний Ветер'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4df065-c0e8-4f0d-85e8-13d3d7739704",
   "metadata": {},
   "source": [
    "- Все эти удаленные фичи, не вносят особо никакой вклад в модели, исходя из анализа важности фичей трех вышеперечисленных методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc19b8-cfd2-4545-a29d-bd109db94d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на новый DataFrame\n",
    "df_new_two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98940af0-ed13-40ce-b091-3df63df27fac",
   "metadata": {},
   "source": [
    "- По итогу получилась не совсем \"красивая\" матрица корреляции. Но, достоверно известно, что **лишние столбцы удалены не были**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0262b4c-1673-44fe-a229-622586ed380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_new_two.corr()\n",
    "\n",
    "plt.figure(figsize=(6.5, 6.5))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar=False)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7cf56-a191-4c69-8fe9-93120f873dee",
   "metadata": {},
   "source": [
    "## Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc698aee-5626-4633-8ae2-ffa82da77646",
   "metadata": {},
   "source": [
    "- Протестируем на новом DataFrame, несколько методов ML:\n",
    "  - Еще раз прогоним Extreme Gradient Boosting;\n",
    "  - Протестируем метод ближайших соседей;\n",
    "  - Протестируем Random Forest.\n",
    "\n",
    "- Метод CatBoost использовать не буду, т.к он показал себя так же как и метод XGBoost, но обучался на тренировочных данных значительно дольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcf3e3-f1d0-4426-bc65-606f35344e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обозначим целевую переменную и остальные параметры как X и y\n",
    "X = df_new_two.drop(['Гармония Бессмертия'], axis = 1)\n",
    "y = df_new_two['Гармония Бессмертия']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31830d-043f-480e-9978-83892c0e784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf61b6-0bae-49ef-8d94-72eaee25befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем данные на тестовую и тренировочную выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state=200) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b77ac1-1d67-4842-963d-34e0d9b1e07a",
   "metadata": {},
   "source": [
    "## Метод: Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d894d-4acb-4a68-adae-825a28e027e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='mae')\n",
    "\n",
    "# Запишем необходимые нам параметры для дальнейшего перебора.\n",
    "param_xgb = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'learning_rate': [0.1, 0.2],  \n",
    "    'max_depth': [3, 5, 10],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]    \n",
    "}\n",
    "\n",
    "# Сделаем перебор заданных выше параметров, при этом разделив выборку данных на 5 частей.\n",
    "grid_search__xgb = GridSearchCV(xgb_regressor, param_xgb, cv=5)\n",
    "\n",
    "# Обучим модель на тренировочных данных\n",
    "grid_search__xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d3255-b30d-430c-aad8-5cd6e7a81afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим лучшие параметры, дающие максимальный прирост Information gain\n",
    "grid_search__xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ce22f-193d-4cce-8c77-8eb447601f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним эти параметры в новую переменную, чтобы далее с ними работать\n",
    "best_gs_xgb_two = grid_search__xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce124e00-7cfa-45c3-935a-ef9562affe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_gs_xgb_two.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_gs_xgb_two.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3eba50-433c-4c61-82ec-5e53ee924a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_gs_xgb_two.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c73a35-b215-4f56-a6d2-b6d46ddd3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e265f-182d-4f7d-8fb6-26e11dcd2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db3cc1-7edc-4999-9095-9622fd754df8",
   "metadata": {},
   "source": [
    "## Метод Ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2e179-f114-49b6-9d0e-563ca879a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "\n",
    "param_knn = {\n",
    "    'n_neighbors': range(1, 30),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree'],\n",
    "    'leaf_size': range(10, 50, 5)}\n",
    "\n",
    "grid_search_knn2 = GridSearchCV(knn, param_knn, cv=5)\n",
    "grid_search_knn2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad06304-0fed-4ead-9b49-2029e9504029",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_knn2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f13d76-3c6e-4b88-916b-2778c234ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним эти параметры в новую переменную, чтобы далее с ними работать\n",
    "best_gs_knn2 = grid_search_knn2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256eec6c-9dd4-48b6-8ba6-db033cea3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_gs_knn2.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_gs_knn2.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491eea8-89a7-4e42-bd78-26381f0f0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_gs_knn2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14684d91-871e-4bc4-ae3c-64078ccfd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bc499-4c9a-4ead-8745-2622bed61f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e29553-f413-474b-a385-506d09270f6b",
   "metadata": {},
   "source": [
    "## Метод: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a52481-8023-4c39-b3dc-0b84bf46be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_forest = RandomForestRegressor()\n",
    "\n",
    "parametrs_fr = {'max_depth':[3, 5, 10],\n",
    "              'n_estimators':[10, 100, 200],\n",
    "              'max_features':[1, 3, 5, 7]}\n",
    "\n",
    "grid_search_reg_forest2 = GridSearchCV(reg_forest, parametrs_fr, cv = 5)\n",
    "grid_search_reg_forest2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeeacaa-3587-48bc-92f8-a1e5051850f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_reg_forest2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9bcf4-c767-4cba-b69d-9457cd00677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним эти параметры в новую переменную, чтобы далее с ними работать\n",
    "best_rf_reg2 = grid_search_reg_forest2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82687c05-939d-42f1-a5a7-b5ee27b25ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_rf_reg2.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_rf_reg2.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4ed64-0af8-4b93-b346-07da4815949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_rf_reg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f7801-ea05-46c4-9e37-d22005a2993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f6f8e-5348-4fb6-b230-0806074dd697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ffb2a-3855-41e4-b0ce-08ba4ec790d9",
   "metadata": {},
   "source": [
    "## Протестируем модели на разных разбиениях данных и на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3eee8-2f30-464a-84fe-8d8fecee7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new_two.drop(['Гармония Бессмертия'], axis=1)\n",
    "y = df_new_two['Гармония Бессмертия']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690585c5-627b-445e-be09-0d8ee73eba95",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955063d-3f38-48cd-b130-94e8f8b3e025",
   "metadata": {},
   "source": [
    "- Оценим, как модель показывает себя, метрику Score и MAE, на нескольких разбиениях, при изменении random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ddc43b-700a-494c-80ed-e7254b533871",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "test_scores = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=400 + i)\n",
    "    \n",
    "    y_pred = best_gs_xgb_two.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    score = best_gs_xgb_two.score(X_test, y_test)  \n",
    "    \n",
    "    test_scores.append({'run': i + 1, 'Score': score, 'MAE': mae})\n",
    "\n",
    "test_scores_df_xgb = pd.DataFrame(test_scores)\n",
    "print(test_scores_df_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4ad1f-551f-40de-8d11-6b5ca4f66af3",
   "metadata": {},
   "source": [
    "- Показатели Score и MAE стабильные и хорошие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff382cfd-da56-47cd-9cc7-c7025bcc005f",
   "metadata": {},
   "source": [
    "#### Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118171f1-2425-4e79-a70d-c08bf404b4ff",
   "metadata": {},
   "source": [
    "- Необходимо оценить, **нет ли** у моделей **переобучения**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114ef95-7031-4061-87a2-276096b8bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(best_gs_xgb_two, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"Среднее значение R^2 при кросс-валидации:\", cv_scores.mean())\n",
    "print(\"Стандартное отклонение R^2:\", cv_scores.std())\n",
    "\n",
    "cv_mae = cross_val_score(best_gs_xgb_two, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"Среднее значение MAE при кросс-валидации:\", -cv_mae.mean())\n",
    "print(\"Стандартное отклонение MAE:\", cv_mae.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4038e-1d6b-4509-89f0-418232209b89",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "```\n",
    "Среднее значение R^2 очень близко к 1 (0.96929), что указывает на высокую точность предсказаний.\n",
    "\n",
    "Стандартное отклонение R^2 маленькое (0.005404), это означает, что модель показывает стабильные результаты на всех 5 разбиениях данных, свидетельствует о надежности модели.\n",
    "\n",
    "Среднее значение MAE мало (0.000707), что говорит о высокой точности предсказаний.\n",
    "\n",
    "Стандартное отклонение MAE очень небольшое (~3.57e-05), что дополнительно подтверждает стабильность.\n",
    "```\n",
    "\n",
    "- Можно считать, что переобучения нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635fe9a-8a34-4eb2-ab29-008594322c6e",
   "metadata": {},
   "source": [
    "### Ближайшие соседи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fddd04-24d5-4f2b-bd4b-27ed3bc2c82a",
   "metadata": {},
   "source": [
    "- Оценим, как модель показывает себя, метрику Score и MAE, на нескольких разбиениях, при изменении random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc594472-35d0-4198-a268-afc23130be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "test_scores = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=400 + i)\n",
    "    \n",
    "    y_pred = best_gs_knn2.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    score = best_gs_knn2.score(X_test, y_test) \n",
    "    \n",
    "    test_scores.append({'run': i + 1, 'Score': score, 'MAE': mae})\n",
    "\n",
    "test_scores_df_knn = pd.DataFrame(test_scores)\n",
    "print(test_scores_df_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df9da0a-1fcc-42cd-af20-6830cc19f9dd",
   "metadata": {},
   "source": [
    "- Показатели Score и MAE стабильные и хорошие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc434514-3ea6-4401-a2bd-dc4ab6e78a62",
   "metadata": {},
   "source": [
    "#### Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ef67c-7f6d-4a7d-b2ad-affc5573a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(best_gs_knn2, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"Среднее значение R^2 при кросс-валидации:\", cv_scores.mean())\n",
    "print(\"Стандартное отклонение R^2:\", cv_scores.std())\n",
    "\n",
    "cv_mae = cross_val_score(best_gs_knn2, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"Среднее значение MAE при кросс-валидации:\", -cv_mae.mean())\n",
    "print(\"Стандартное отклонение MAE:\", cv_mae.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e1ae8-ef64-4786-ac49-e6bd3fa79c88",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "```\n",
    "Среднее значение R^2 очень близко к 1 (0.99156), высокая точность предсказаний.\n",
    "\n",
    "Стандартное отклонение R^2 маленькое (0.000503), свидетельствует о надежности модели.\n",
    "\n",
    "Среднее значение MAE мало (0.000523), что говорит о высокой точности предсказаний.\n",
    "\n",
    "Стандартное отклонение MAE небольшое (~9.08e-06), дополнительно подтверждает стабильность.\n",
    "```\n",
    "\n",
    "- Можно считать, что переобучения нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd8574-82a4-4abc-8f96-e24dd38e5337",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83dda1-1c2b-42dd-9e14-5ba3ea03ece0",
   "metadata": {},
   "source": [
    "- Оценим, как модель показывает себя, метрику Score и MAE, на нескольких разбиениях, при изменении random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711547a-d716-4d0a-9305-1417306697a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "test_scores = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=400 + i)\n",
    "    \n",
    "    y_pred = best_rf_reg2.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    score = best_rf_reg2.score(X_test, y_test)  \n",
    "    \n",
    "    test_scores.append({'run': i + 1, 'Score': score, 'MAE': mae})\n",
    "\n",
    "test_scores_df_rf = pd.DataFrame(test_scores)\n",
    "print(test_scores_df_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bece4f-d75a-45d0-8fb3-483fc75b9a47",
   "metadata": {},
   "source": [
    "- Показатели Score и MAE стабильные и хорошие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4656dda-9a96-4b8f-aa52-cbcd68fec6ad",
   "metadata": {},
   "source": [
    "#### Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51369a-89a8-439c-9a7c-5f4c606ae8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(best_rf_reg2, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"Среднее значение R^2 при кросс-валидации:\", cv_scores.mean())\n",
    "print(\"Стандартное отклонение R^2:\", cv_scores.std())\n",
    "\n",
    "cv_mae = cross_val_score(best_rf_reg2, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"Среднее значение MAE при кросс-валидации:\", -cv_mae.mean())\n",
    "print(\"Стандартное отклонение MAE:\", cv_mae.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab25dd-0dcd-426f-97d6-070c86f1c4ae",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "```\n",
    "Среднее значение R^2 близко к 1 (0.98606), говорит о высокой точности предсказаний.\n",
    "\n",
    "Стандартное отклонение R^2 маленькое (0.001612), свидетельствует о надежности модели.\n",
    "\n",
    "Среднее значение MAE мало (0.000607), говорит о высокой точности предсказаний.\n",
    "\n",
    "Стандартное отклонение MAE небольшое (~9.23e-06), это дополнительно подтверждает стабильность.\n",
    "```\n",
    "\n",
    "- Можно считать, что переобучения нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2d49c-49ad-4e8b-9d23-020668d345ff",
   "metadata": {},
   "source": [
    "Построим для этих трех методов график распределения предсказанных и истинных значений на плоскости. И оценим точность предсказания на тестовых данных - визуально."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab247d7c-556b-4799-9a2b-5833a87965f0",
   "metadata": {},
   "source": [
    "## Scatter Plot - Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c879b-deca-47db-b55b-d3af994cb682",
   "metadata": {},
   "source": [
    "- Отобразим визуально на графике истинные и предсказанные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9504f5-4d57-41c0-8fa7-a85034597c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_gs_xgb_two.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') \n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448bfac-f4f5-4c59-9d76-fb03c2d70172",
   "metadata": {},
   "source": [
    "- XGBoost имеет отличное распределение точек на плоскости, практически все точки на диагональной прямой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8032c-146a-44b7-8105-987267987f84",
   "metadata": {},
   "source": [
    "## Scatter Plot - K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a969270-72f6-47e4-8ab9-e4dac3ddcbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_gs_knn2.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') \n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('K-Nearest Neighbor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c44ae-86c3-4cb2-90f2-5ca1f02575b1",
   "metadata": {},
   "source": [
    "- K-Nearest Neighbor так же имеет хорошее распределение точек на плоскости, но заметно, что точки лежат немного хуже, немного откланяются от диагональной прямой по сравнению с XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf277e3-3d35-414e-9b67-7d90756d5aa4",
   "metadata": {},
   "source": [
    "## Scatter Plot - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3eaf8-8a25-451a-8c58-01ada9023da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_rf_reg2.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') \n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c054340-87b4-4405-9c3a-ae81adc52846",
   "metadata": {},
   "source": [
    "- У метода Random Forest картинка примерна схожа с методом K-Nearest Neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823b91d-77bd-490b-ae04-1d03e5eeade7",
   "metadata": {},
   "source": [
    "## Итог варианта решения №1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f31f4-4560-415f-8fdb-8fdefd068304",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- В результате решения первым методом, удаление столбцов в DataFrame производилось не с точки зрения оценки корреляции, а с точки зрения значимости этих столбов для модели ML.\n",
    "- Даже если столбец сильно кореллирует с другими фичами и не коррелирует с целевой переменной, его мы не удаляем, т.к. он может быть потенциально полезен для модели ML.\n",
    "    - Возьмем для примера фичу \"Ритм магического ядра\", которая коррелирует с целевой переменной на -0.00 и сильно коррелирует с другими столбцами. При чистке DataFrame и удалении всех коррелирующих стобцов, чтобы прийти к матрице корреляции которая нас устроит, мы бы попросту избавились от фичи \"Ритм магического ядра\", как и было сделано в варианте решения №2. Но, с точки зрения важности параметров (было проанализировано выше), эта фича входит в топ-6 параметров по значимости и однозначно вносит свой вклад в более точное обучение ML. Да, мы получаем не совсем красивую матрицу корреляции, но и не удаляем важные фичи для обучения модели.\n",
    " \n",
    "**Результаты**:\n",
    "```\n",
    "Метод: Extreme Gradient Boosting\n",
    "    - Score на тренировочных данных =  0.9995\n",
    "    - Score на тестовых данных =  0.9993\n",
    "    - MAE на тестовых данных = 0.0001\n",
    "\n",
    "Метод: K-Nearest Neighbor\n",
    "    - Score на тренировочных данных =  1.0\n",
    "    - Score на тестовых данных =  0.9937\n",
    "    - MAE на тестовых данных = 0.0005\n",
    "\n",
    "Метод: Random Forest\n",
    "    - Score на тренировочных данных =  0.9898\n",
    "    - Score на тестовых данных =  0.9876\n",
    "    - MAE на тестовых данных = 0.0006\n",
    "```\n",
    "\n",
    "Все модели показали себя очень хорошо! \n",
    "\n",
    "**Лучшая модель**:\n",
    "```\n",
    "С точки зрения метрики Score и с точки зрения метрики MAE, лучше всего себя показал метод: Extreme Gradient Boosting.\n",
    "\n",
    "Он имеет как самое высокое значение точности, так и самую быструю скорость обучения.\n",
    "```\n",
    "\n",
    "Построен Scatter Plot, на котором показано распределение точек на плоскости, предсказанные и истинные значения. Видим, что большинство точек лежит именно на красной линии, на диагонали, что сведетельствует о точных предсказаниях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e06df-130a-4d34-b125-d8c1f57037ac",
   "metadata": {},
   "source": [
    "# Вариант №2 - избавляемся от коррелирующих столбцов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eaaac5-4195-41f4-bf25-674bb0b853f0",
   "metadata": {},
   "source": [
    "- В данном варианте №2, принято решение избавиться от корелирующих и мультиколлинеарных значений, т.к большая кореляция потенциально не очень хорошо влияет на модели. Будем заниматься чисткой данных.\n",
    "\n",
    "- Еще раз выведем **общую** корреляционную матрицу после добавления **всех** гиперпараметров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6f642-b4ba-49b5-8b9e-b6994bac3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_new.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar=False)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728758e-9ea9-406b-9066-f924b92e129f",
   "metadata": {},
   "source": [
    "- **Т.к в корелляционной матрице очень много сильно коррелирующих значений, от них нужно избавляться.**\n",
    "\n",
    "- Для начала удалим параметры, на основе которых были созданы новые столбцы. Т.к они **сильно** коррелируют с новыми столбцами и **слабо** коррелируют с целевой переменной.\n",
    "\n",
    "- Оценим, что получилось, снова взглянув на матрицу корреляции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f5f5d-5142-462d-a86c-bd5c63d17b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем сильно коррелирующие значения\n",
    "df_new = df_new.drop(['Сила Левого Потока', 'Сила Правого Потока', 'Приток Силы Потока'], axis = 1) # Удаляем, так как на основе этих параметров создан новый \"Полная мощность потоков\" и они с ним сильно коррелируют.\n",
    "df_new = df_new.drop(['Ритм магического ядра', 'Эмульсия Истока'], axis = 1) # Удаляем, так как на основе этих параметров создан новый \"Эффективность ядра\" и они с ним сильно коррелируют.\n",
    "df_new = df_new.drop(['Температура выдоха Истока', 'Древний Ветер'], axis = 1) # Удалим эти параметры, тк они содержат по 9547 пропусков и коррелируют на значение \"1.00\" с \"Полная мощность потоков\"\n",
    "df_new = df_new.drop(['Приток давления Выдоха Истока', 'Давление выдоха Истока'], axis = 1) # Удалим эти параметры, тк на основе них создан параметр \"Общее давление.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5a893-4c6d-4d92-840e-9871003a96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим корреляцию после частичного удаления коррелирующих переменных.\n",
    "correlation_matrix = df_new.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar=False)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b4127-881f-4751-a16b-86f523ae61d4",
   "metadata": {},
   "source": [
    "- Ситуация стала немного лучше. Продолжаем удалять стобцы и сильно коррелирующие значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1ceb3-4e03-4f1a-8083-91f609e21147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Удаляем сильно коррелирующие значения\n",
    "df_new = df_new.drop(['Вектор Мощи', 'Скорость перехода через портал', 'Поток Энергий'], axis = 1) # Сильно коррелируют с \"Эффективность ядра\" и не коррелируют с Целевой переменной.\n",
    "df_new = df_new.drop(['Пламя Стихий', 'Печать Чародея', 'Полная мощность потоков', 'Общее давление'], axis = 1) # Сильно коррелируют с \"Эффективность ядра\" и не коррелируют с Целевой переменной.\n",
    "df_new = df_new.drop(['Дыхание Истока'], axis = 1) # Сильно коррелируют с разными параметрыми и не коррелируют с Целевой переменной.\n",
    "df_new = df_new.drop(['Разница стабильности'], axis = 1) # Сильно коррелирует с \"Степень износа\": -0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0a412-cb19-438e-b07f-d44eb81ef2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим корреляцию после частичного удаления коррелирующих переменных.\n",
    "correlation_matrix = df_new.corr()\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar=False)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6a142-8ac2-43fd-a71a-baad5bb847db",
   "metadata": {},
   "source": [
    "- В корреляционной матрице осталось еще одно **высокое** значение корреляции.\n",
    "  \n",
    "    - Это корреляция между 'Общая мощность ядра' и 'Эффективность ядра', равная **0.90**.\n",
    " \n",
    "    - После взвешивания двух параметров, их влияния (корреляции) на целевую переменную 'Гармония Бессмертия', был выбран для удаления параметр, с меньшей корреляцией. Это 'Общая мощность ядра' с корреляцией = 0.00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37daeb0a-547b-4869-8107-c999eaf7ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(['Общая мощность ядра'], axis = 1) # Сильно коррелирует с \"Эффективность ядра\": 0.90 и 0.00 с целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06142a2b-d4ec-448e-8653-a91aefa8853b",
   "metadata": {},
   "source": [
    "- Полученные **итоговые** значения корреляции приемлемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990cc7f1-0f38-491c-99ff-599f86c2b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим корреляцию после Полного удаления коррелирующих переменных.\n",
    "correlation_matrix = df_new.corr()\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar=False)\n",
    "plt.title('Матрица корреляции')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af39cd3-fc3a-4f5d-a931-f07f46a4918e",
   "metadata": {},
   "source": [
    "- Оценим количество выбросов среди новых столбцов DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b3f07-6167-498a-9a0c-9b6215eaa376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим графики boxplot для каждого столбца нового DataFrame, для оценки выбросов.\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "sns.boxplot(x=df_new['Гармония Бессмертия'], ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Гармония Бессмертия')\n",
    "\n",
    "sns.boxplot(x=df_new['Магическая производительность'], ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Магическая производительность')\n",
    "\n",
    "sns.boxplot(x=df_new['Эффективность ядра'], ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Эффективность ядра')\n",
    "\n",
    "sns.boxplot(x=df_new['Степень износа'], ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Степень износа')\n",
    "\n",
    "sns.boxplot(x=df_new['Баланс угасания'], ax=axes[2, 0])\n",
    "axes[2, 0].set_title('Баланс угасания')\n",
    "\n",
    "fig.delaxes(axes[2, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc63381-7964-441a-bcbb-ab70f883c909",
   "metadata": {},
   "source": [
    "- Видим, что большое количество выбросов есть у параметра \"Баланс угасания\".\n",
    "\n",
    "- Посчитаем их количество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df063fc-f5d7-4aaa-acb2-53a88b524b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитаем количество выбросов для параметра \"Баланс угасания\"\n",
    "# Квартиль и межквартильный размах для нашего параметра \"Баланс угасания\"\n",
    "Q1 = df_new['Баланс угасания'].quantile(0.25)\n",
    "Q3 = df_new['Баланс угасания'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Границы для выбросов\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Находим сами выбросы\n",
    "outliers = df_new[(df_new['Баланс угасания'] < lower_bound) | (df_new['Баланс угасания'] > upper_bound)]\n",
    "\n",
    "# Считаем их количество\n",
    "num_outliers = outliers.shape[0]\n",
    "\n",
    "print(f'Количество выбросов параметра \"Баланс угасания\": {num_outliers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660abe3-7f78-4547-920e-23becac8f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим, преимущественно какие значения присуще параметру 'Баланс угасания'\n",
    "df_new['Баланс угасания'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e700b-6597-4f5a-b1f6-c8573b5369f3",
   "metadata": {},
   "source": [
    "- Выявлено, что большое количество выбросов (1098) у столбца 'Баланс угасания'.\n",
    "\n",
    "- Появляется необходимость использования **масштабирования данных**, т.к данные выбросы, потенциально могут негативно сказаться на дальнейших моделях ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe654735-4a08-4765-a1bf-5d7be389052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим распределение параметров нового DataFrame\n",
    "features = list(set(df_new))\n",
    "\n",
    "df_new[features].hist(figsize=(11, 11));\n",
    "\n",
    "# Видим что распределение параметра 'Баланс угасания', сконцентрировано у значения 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc1a29-401d-434c-993f-c090942484fc",
   "metadata": {},
   "source": [
    "- На графике видно какое не нормальное распределение у \"Баланс угасания\", из-за большого количества выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160ff00-2322-4486-af92-096dd8fed8d4",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e932dc-0f2c-437c-a869-89e38d7d2d3a",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ae52f-7477-4857-ba42-d46d66bac824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обозначим целевую переменную и остальные параметры как X и y\n",
    "X = df_new.drop(['Гармония Бессмертия'], axis = 1)\n",
    "y = df_new['Гармония Бессмертия']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4dc0f1-5969-467a-a2e9-b833d94a9c63",
   "metadata": {},
   "source": [
    "Проведем масштабирование данных, т.к к примеру, такой параметр, как \"Баланс угасания\" имеет большое количество выбросов. \n",
    "\n",
    "Тем самым, **нормализуем данные** и сделаем их более пригодными для дальнейших алгоритмов, менее заметными (т.к наличие выбросов \n",
    "может сильно сказаться на их результатах)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b89d5c-72f6-4182-87f9-2810a2834754",
   "metadata": {},
   "source": [
    "## Масштабирование данных: StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9ea05-2980-4781-9d08-3681adf1bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be7038-bd1e-4675-989b-b924b9f21686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем данные на тестовую и тренировочную выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=150) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f866a-0741-4628-8b45-3c4c2da490cd",
   "metadata": {},
   "source": [
    "#### Выбор методов ML\n",
    "\n",
    "Я выбрал 5 методов для решения данной задачи регресии. \n",
    "\n",
    "- Решающие деревья\n",
    "- Случайный лес\n",
    "- Ближайшие соседи\n",
    "- Линейная регрессия\n",
    "- XGBoost\n",
    "\n",
    "Классический метод линейной регресии, выбрал его для задачи регресии.\n",
    "\n",
    "Деревья решений, оценим как они справятся с задачей.\n",
    "\n",
    "Методы ансамблей: Случайный лес и XGBoost. XGBoost - метод быстрее чем Градиентный бустинг, поэтому выбрал его. Случайный лес, как правило более сильный относительно деревьев решений, его необходимо тоже протиестировать.\n",
    "\n",
    "Ближайшие соседи - оценивая преимущественно какие значения присуще целевой переменной 'Гармония Бессмертия', видно что большая часть значений сконцентрировано очень близко (от 0.975 до 1). Это может выйти сильной стороной для метода ближайшх соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c1706-9a66-4c6a-a92f-54e92e6d1e60",
   "metadata": {},
   "source": [
    "#### Выбор метрики ошибки\n",
    "\n",
    "- Изначально я оцениваю модель по **коэффициенту детерминации** (score), для тестовых и тренировочных данных.\n",
    "\n",
    "- Далее оценивается метрика **Mean Absolute Error (MAE)** - среднее значение абсолютной разницы между прогнозами и фактическими наблюдениями. Эта метрика необходима для оценки точности модели и сравнения их между собой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f845bd-5971-4ed4-a0dd-c20cd0324e42",
   "metadata": {},
   "source": [
    "## Метод 1: Решающие деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37731db5-b02d-445d-a0ab-23bb5a74edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regres = DecisionTreeRegressor() # Вызываем классификаторю\n",
    "\n",
    "# В переменной parametrs расписываем все нужные параметры, которые будут перебираться в кросс-валлидации, для выявления лучших из них.\n",
    "parametrs = {'criterion': ['squared_error'], 'max_depth': range(1, 10), 'max_features': range(1, 10), 'min_samples_leaf': range(1, 20)}\n",
    "\n",
    "# Прогонка в кросс-валидации классификатора с заданными выше параметрами, разбивая данные df_new на 5 частей. И используя каждую из 5 частей для тестов.\n",
    "grid_search_cv_regres = GridSearchCV(regres, parametrs, cv = 5)\n",
    "\n",
    "# Обучаем модель на тренировочных данных.\n",
    "grid_search_cv_regres.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ef4c1-8b07-44be-a2db-ef22db12f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим лучшие параметры, по итогу кросс-валидации.\n",
    "grid_search_cv_regres.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29777845-8c1b-4a38-bf23-34b332e471d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним эти параметры в новый, \"лучший\" классификатор.\n",
    "best_clf = grid_search_cv_regres.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd483a4f-15b2-446d-b1c9-b8fd4be21a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим значение score на тренировочных и тестовых данных\n",
    "print('Score на тренировочных данных = ', round(best_clf.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_clf.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439834a-35d7-4a6f-8646-8c9b79b52d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec533a-8c9f-47c9-9723-fcf61c633344",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a99980-1082-46c9-b489-6648a3e2ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb20cb6-c9b5-47d0-9d78-c53cd41023b1",
   "metadata": {},
   "source": [
    "## Метод 2: Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a10c1-9796-4e6f-b6e3-52d06db41d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_forest = RandomForestRegressor()\n",
    "\n",
    "parametrs_fr = {'max_depth':[3, 5, 10],\n",
    "              'n_estimators':[10, 100, 200],\n",
    "              'max_features':[1, 3, 5, 7]}\n",
    "\n",
    "grid_search_reg_forest = GridSearchCV(reg_forest, parametrs_fr, cv = 5)\n",
    "grid_search_reg_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28be915-4fe0-4acf-b6d4-b4972740e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_reg_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d68893-f505-4347-a8a4-f3334df8f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_rf = grid_search_reg_forest.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f91931-faaf-4f15-a82e-86638721d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_reg_rf.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_reg_rf.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c805dfe-0fd4-4b93-b9dd-00f229d2330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_reg_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e3d30-2957-4727-bd7d-b5ab8dfa95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e33f6-aa3e-4b08-817c-879c849adeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fc83c-b133-47fb-a658-fc3ed8cca707",
   "metadata": {},
   "source": [
    "## Метод 3: Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1c6b6-c28e-463e-b8fe-f68ebf8970b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "\n",
    "param_knn = {\n",
    "    'n_neighbors': range(1, 30),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree'],\n",
    "    'leaf_size': range(10, 50, 5)}\n",
    "\n",
    "grid_search_knn = GridSearchCV(knn, param_knn, cv=5)\n",
    "grid_search_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15504253-6a09-445e-9f86-0cf573101cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceecf23-906f-465d-ab87-0ee7969f3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_knn = grid_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c8cba-0021-40e1-8eb1-e7482b4504f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_clf_knn.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_clf_knn.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a469d-7e88-42c4-ab83-ee987a8eacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_clf_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e286672-8edf-42c5-8e30-895276cd9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e9666-ff02-4637-92d9-783dfb66f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cdbd6b-307b-4657-ab8b-c5e10ce45222",
   "metadata": {},
   "source": [
    "## Метод 4: Линейная Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f2105-be7a-4392-9e2d-99b3b196225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "param_lr = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'n_jobs': [-1]}\n",
    "\n",
    "grid_search_lr = GridSearchCV(lin_reg, param_lr, cv=5)\n",
    "grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7558745-ffc8-456f-977b-8ccdcda1d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea3211-ab58-4b14-b72e-f29229afc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lin_reg = grid_search_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4880d48-6d7d-4c52-bcc8-c10403bb7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_lin_reg.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_lin_reg.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743711f-de7b-46fb-98c1-7897e647ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92463ea9-82d1-4335-9f2c-a69e0d4f792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9170043-97d1-4d29-95d5-9712f24d4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f16bb2-b598-4847-97aa-717ee76a8fee",
   "metadata": {},
   "source": [
    "## Метод 5: Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce0c20-9814-4911-baab-78ac60c3579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='mae')\n",
    "\n",
    "param_xgb = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'learning_rate': [0.1, 0.2],  \n",
    "    'max_depth': [3, 5, 10],\n",
    "    'subsample': [0.8, 1.0]}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(xgb_regressor, param_xgb, cv=5)\n",
    "\n",
    "grid_search_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e31358-3635-4f62-a233-bb410e01af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c718057-8165-453e-8b6c-312bcfb1d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_search_xgb = grid_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b248337-c95d-4123-bf29-eccfd71382b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_grid_search_xgb.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_grid_search_xgb.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b7a16-b199-4049-88b6-24f30e3b7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_grid_search_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d64a5d-2b16-4f46-85e2-596b973e36a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532d330-74d2-4174-8d4b-b7e8d44d3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd697177-7563-405b-af54-1fe0435e3088",
   "metadata": {},
   "source": [
    "- Визуально оценим распределение истинных и предсказанных значений на плоскости.\n",
    "\n",
    "- Выбрал два самых лучших метода исходя из метрик ошибки (Метод ближайших соседей и Extreme Gradient Boosting).\n",
    "\n",
    "- Построим для них распределение точен на Scatter Plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ca08b-e001-4aab-9f80-148680f444f9",
   "metadata": {},
   "source": [
    "## Scatter Plot - Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67f781-1aeb-43c2-b37f-25e523da8ba3",
   "metadata": {},
   "source": [
    "- Оценим визуально распределение предсказанных и истинных значений на графике Scatter Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d5129-fbfb-4e97-838b-e6e33fe4b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_clf_knn.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') \n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a407706-07d8-42ca-9f94-0030a34a432e",
   "metadata": {},
   "source": [
    "- Видно определенное количество точек, которые сильно смещены относительно диагонали."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244140b-c4f0-4c19-825e-7bc0e786efbe",
   "metadata": {},
   "source": [
    "## Scatter Plot - Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae2f36-5984-499f-96ea-d12fbe8219fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_grid_search_xgb.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') \n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f6982-4f19-4be5-a3be-09d779ec3caf",
   "metadata": {},
   "source": [
    "- У XGBoost таких точек, отклюняющихся от диагональной прямой уже меньше. Картина выглядит лучше.\n",
    "\n",
    "- Это предсказуемо, т.к. MAE у XGBoost меньше чем у метода kNN (0.0006 и 0.0009) соответственно. Это говорит о **меньшей ошибки** предсказанного значения относительно истинного, следовательно и отклонение точки от красной диагональной прямой меньше, как по количеству, так и по удаленности от нее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2badc818-8721-44b1-9980-f0545ca9491e",
   "metadata": {},
   "source": [
    "## Масштабирование данных: RobustScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d9b1d-6138-4e3b-a56f-faf9c46ddcec",
   "metadata": {},
   "source": [
    "Имея выбросы только в одном параметре 'Баланс угасания'. Попробуем провести масштабироване только одной переменной спользуя \n",
    "\"RobustScaler\". \n",
    "\n",
    "RobustScaler - масштабирует данные, используя медиану и интерквартильный размах, что делает его менее чувствительным к выбросам. \n",
    "\n",
    "StandardScaler, использует среднее и стандартное отклонение. При наличии выбросов в данных стандартное шкалирование может быть неэффективным, т.к оно чувствительно к экстремальным значениям. Стандартное отклонение и среднее сильно смещаются выбросами, что приводит к некорректному масштабированию остальных значений.\n",
    "\n",
    "Протестируем вариант масштабирования с помощью \"RobustScaler\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b5dd7-7c26-4fc0-97df-2cc83e57e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_new.drop(['Гармония Бессмертия', 'Баланс угасания'], axis = 1)\n",
    "y_new = df_new['Гармония Бессмертия']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23974d5c-3ccf-422d-82e9-f30cd11757ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5ce59-746e-42be-880b-24a2180b04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем результат обратно в DataFrame.\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a4939-1701-4d79-be4b-2c1a4a36a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем масштабирование данных только переменной 'Баланс угасания'\n",
    "scaler_rob = RobustScaler()\n",
    "\n",
    "balance_sc = scaler_rob.fit_transform(df_new[['Баланс угасания']])\n",
    "\n",
    "X_scaled['Баланс угасания'] = balance_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3317a-4cdb-42a6-ab20-e18644e09715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем данные на тестовую и тренировочную выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_new, test_size = 0.33, random_state=200) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d5ca8-0e45-45a7-b393-740bc15b3636",
   "metadata": {},
   "source": [
    "## Метод 1: Решающие деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ccfe5-a504-48f5-abde-1202e495b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regres_two = DecisionTreeRegressor()\n",
    "\n",
    "parametrs = {'criterion': ['squared_error'], 'max_depth': range(1, 10), 'max_features': range(1, 10), 'min_samples_leaf': range(1, 20)}\n",
    "\n",
    "grid_search_cv_regres_two = GridSearchCV(regres_two, parametrs, cv = 5)\n",
    "grid_search_cv_regres_two.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01725504-2648-4677-a191-03186c1398a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv_regres_two.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49358f4d-ec46-4a9b-bf9e-157194f33fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_two = grid_search_cv_regres_two.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392b557-6572-450a-be50-345cc4365c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_clf_two.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_clf_two.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82cab94-94d1-406f-9d85-1ec38709135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_clf_two.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec35b96-f398-429a-ab23-5721f072353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41a743-e2dd-4872-9873-2ed9bff8e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763339b0-3962-44c4-9b64-194946e66226",
   "metadata": {},
   "source": [
    "## Метод 2: Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6b901-b381-4e96-9705-3ac73d914b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_forest_two = RandomForestRegressor()\n",
    "\n",
    "parametrs_fr = {'max_depth':[3, 5, 10],\n",
    "              'n_estimators':[10, 100, 200],\n",
    "              'max_features':[1, 3, 5, 7]}\n",
    "\n",
    "grid_search_reg_forest_two = GridSearchCV(reg_forest_two, parametrs_fr, cv = 5)\n",
    "grid_search_reg_forest_two.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c85954-35d5-43c1-b409-baed921531f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_reg_forest_two.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b02802-29be-48f1-91ae-129d0a5bb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_rf_two = grid_search_reg_forest_two.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d0e68-312c-42e8-88e7-655de1c4ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_reg_rf_two.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_reg_rf_two.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7160f28-09f8-4c3c-856d-7a3c25c23787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_reg_rf_two.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08084e2a-bc3d-4a06-9066-946a6dbe5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9eca96-285e-4258-b127-822b6cf83bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b8a33b-a4d2-4947-aff4-0682ee2709db",
   "metadata": {},
   "source": [
    "## Метод 3: Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f7eee-dc17-4bdc-a4a4-8d7095b78581",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_two = KNeighborsRegressor()\n",
    "\n",
    "param_knn = {\n",
    "    'n_neighbors': range(1, 30),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree'],\n",
    "    'leaf_size': range(10, 50, 5)}\n",
    "\n",
    "grid_search_knn_two = GridSearchCV(knn_two, param_knn, cv=5)\n",
    "grid_search_knn_two.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6164c26f-05fe-4c41-a260-e770778786ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_knn_two.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e7697-104d-445a-a156-e02c4a3a7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_knn_two = grid_search_knn_two.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345bc92-43ec-4800-9115-60adce33aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_clf_knn_two.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_clf_knn_two.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ff708-a536-4187-bcc2-16f927dfb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_clf_knn_two.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61c003-7b00-45ba-b30d-135bd4161bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24fc2d-14c8-4dc2-80c9-739cd1e45ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8278d-121d-4a71-baea-c790a733b61a",
   "metadata": {},
   "source": [
    "## Метод 4: Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f980d-751e-493e-8672-2639e69f705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor_two = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='mae')\n",
    "\n",
    "param_xgb = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'learning_rate': [0.1, 0.2],  \n",
    "    'max_depth': [3, 5, 10],\n",
    "    'subsample': [0.8, 1.0]}\n",
    "\n",
    "grid_search_xgb_two = GridSearchCV(xgb_regressor_two, param_xgb, cv=5)\n",
    "\n",
    "grid_search_xgb_two.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e17bdd-8a8a-4ac6-90ab-e2d518947a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb_two.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46209d2-ef61-4e95-93ba-3515a0323a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_search_xgb_two = grid_search_xgb_two.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03427b0e-5c6f-48d1-8a2f-a6ad29070c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score на тренировочных данных = ', round(best_grid_search_xgb_two.score(X_train, y_train), 4))\n",
    "print('Score на тестовых данных = ', round(best_grid_search_xgb_two.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687da6c-bc39-4e82-93e8-5ec2fe54c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем среднюю абсолютную ошибку (Mean Absolute Error - MAE)\n",
    "y_test_pred = best_grid_search_xgb_two.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbb152-d2ff-442f-a7ed-25c7f4ff1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e148b-b91e-45e6-91ec-d4ad46d1ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE на тестовых данных =', round(mae_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c8351-f917-4281-b395-b2c183ecfb75",
   "metadata": {},
   "source": [
    "- Построим графики Scatter Plot для визуализации точности истинных и предсказанных значений.\n",
    "\n",
    "- Я выбрал **два** метода, которые показали себя лучше всего по метрике качества:\n",
    "\n",
    "    -  Метод ближайших соседей\n",
    "    -  Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc163cd-3791-4a1a-8d46-c2ef2a359a5b",
   "metadata": {},
   "source": [
    "## Scatter Plot - Метод ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14eb64-16c1-46a6-9037-89fd2ab9e45a",
   "metadata": {},
   "source": [
    "- Оценим визуально распределение предсказанных и истинных значений на графике Scatter Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad1863-0175-4d83-8604-56e96fe808c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_clf_knn_two.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') \n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5580f80-dd90-4c9e-968f-9769bb7490e5",
   "metadata": {},
   "source": [
    "- Картина у метода kNN стала немного хуже, это связано с увеличением MAE, что свидетельствует о более сильном отклонении точек. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed0802-85b0-4741-a8ce-6fe93972a9e0",
   "metadata": {},
   "source": [
    "## Scatter Plot - Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6121cd3-e54f-407b-a95a-bfd27bfa24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_grid_search_xgb_two.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') \n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a646e54-e791-42f4-a600-3d66e0f31e9e",
   "metadata": {},
   "source": [
    "- Картина у XGBoost с изменением масштабирования данных, визуально не поменялась, как и показатель MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ce87c-c0c4-48fa-aab0-269fa0497413",
   "metadata": {},
   "source": [
    "## Итог варианта решения №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08b578-3664-4042-b9a6-aad9544a4478",
   "metadata": {},
   "source": [
    "- Вариант решения №2 заключался в том, чтобы добиться максимально приемлемой корреляционной матрицы. Уйти от той матрицы корреляции, где практически все параметры были мультиколлинеарны и прийти к матрице, где все парраметры приемлемо коррелируют друг с другом. В нашем случае максимальная корреляция составила 0.68, что вполне приемлемо.\n",
    "\n",
    "- Исключение столбцов из DataFrame основывалось на сильной корреляции с другими параметрами и слабой корреляции с целевым столбцом. Изначально удалялись столбцы, из которых получились гиперпараметры (новые столбцы). Ведь при создании гиперпараметра, составляющие его столбцы будут сильно коррелировать с ним, следовательно они будут удалены.\n",
    "\n",
    "- Также протестированы 2 метода масштабирования данных: StandardScaler и RobustScaler. Необходимо было понять, как два разных метода масштабирования повлияют на результаты методов ML. Причиной этому было, большое количество выбросов параметра \"Баланс угасания\". Считалось, что стандартное масштабирование StandardScaler, может быть некомпетентно в данной ситуации.\n",
    "\n",
    "\n",
    "**Результаты:**\n",
    "\n",
    "**1. Масштабирование: StandardScaler**\n",
    "\n",
    "```\n",
    "Метод: Решующие деревья\n",
    "    - Score на тренировочных данных =  0.7418\n",
    "    - Score на тестовых данных =  0.7292 \n",
    "    - MAE на тестовых данных = 0.0028\n",
    "\n",
    "Метод: Random Forest\n",
    "    - Score на тренировочных данных =  0.8872\n",
    "    - Score на тестовых данных =  0.8719\n",
    "    - MAE на тестовых данных = 0.0018\n",
    "\n",
    "Метод: K-Nearest Neighbor\n",
    "    - Score на тренировочных данных =  1.0\n",
    "    - Score на тестовых данных =  0.9578\n",
    "    - MAE на тестовых данных = 0.0009\n",
    "\n",
    "Метод: Линейная Регрессия\n",
    "    - Score на тренировочных данных =  0.2072\n",
    "    - Score на тестовых данных =  0.2211\n",
    "    - MAE на тестовых данных = 0.0056\n",
    "\n",
    "Метод: Extreme Gradient Boosting\n",
    "    - Score на тренировочных данных =  0.9962\n",
    "    - Score на тестовых данных =  0.9741 \n",
    "    - MAE на тестовых данных = 0.0006\n",
    "```\n",
    "\n",
    "**2. Масштабирование: RobustScaler**\n",
    "\n",
    "```\n",
    "Метод: Решующие деревья\n",
    "    - Score на тренировочных данных =  0.7553\n",
    "    - Score на тестовых данных =  0.7346\n",
    "    - MAE на тестовых данных = 0.0028\n",
    "\n",
    "Метод: Random Forest\n",
    "    - Score на тренировочных данных =  0.889\n",
    "    - Score на тестовых данных =  0.8713\n",
    "    - MAE на тестовых данных = 0.0018\n",
    "\n",
    "Метод: K-Nearest Neighbor\n",
    "    - Score на тренировочных данных =  1.0\n",
    "    - Score на тестовых данных =  0.9465\n",
    "    - MAE на тестовых данных = 0.001\n",
    "\n",
    "Метод: Extreme Gradient Boosting\n",
    "    - Score на тренировочных данных =  0.9962\n",
    "    - Score на тестовых данных =  0.9774\n",
    "    - MAE на тестовых данных = 0.0006\n",
    "```\n",
    "\n",
    "\n",
    "- Изменение метода масштабирования (RobustScaler), не дало особо никаких плодов. Сюдя по результатам, показатели моделей наоборот немного ухудшились.\n",
    "\n",
    "**Лучшая модель**\n",
    "\n",
    "```\n",
    "Лучше всего себя показал метод Extreme Gradient Boosting. У него самые высокие показатели точности (коэффициент детерминации - score и метрика ошибки - MAE). Также у данного метода, самая высокая скорость обучения, не считая линейную регрессию (которая показала себя не совсем с лучшей стороны). На изменении масштабирования результаты сильно не поменялись, на тестовых данных при методе RobustScaler, результаты немного выросли.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162ba38-63e5-4761-97a1-e36db42fd73f",
   "metadata": {},
   "source": [
    "# Итоги - Выбор модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338f759-fdd2-4477-80d4-2d91e8fc59c9",
   "metadata": {},
   "source": [
    "В данной работе было протестировано **два** абсолютно разных подхода к решению регрессионной задачи.\n",
    "\n",
    "\n",
    "В **первом варианте** решения был протестирован подход, неудаления корреляционных столбцов в пурвую очередь.\n",
    "```\n",
    "Видно, что обобщенная матрица корреляции, после добавления всех гиперпараметров, имела очень много мультиколинеарных и колинеарных значений (мультиколинеарные - это значения с коэфициентом кореляции меньше единицы и больше 0.7-0.8. А значения с коэфициентом кореляции равным 1 или -1 называются коллинеарными).\n",
    "\n",
    "Была проделана работа по выявлению важности и значимости параметров, перед их удалением.\n",
    "```\n",
    "\n",
    "\n",
    "Во **втором варианте** решения данной регресионной задачи, была проделана большая работа с корреляционной матрицей. Необходимо было привести ее к нормальным значениям корреляции.\n",
    "```\n",
    "Как было указано в итоге варианта решения №2 (Исключение столбцов из DataFrame основывалось на сильной корреляции с другими параметрами и слабой корреляции с целевым столбцом. Изначально удалялись столбцы, из которых получились гиперпараметры. Ведь при создании гиперпараметра, составляющие его столбцы будут сильно коррелировать с ним, следовательно они будут удалены). Большее предпочтение отдавалось именно гиперпараметру, т.к. он состоит из нескольких обычных столбцов и потенциально может нести больше информации для модели, поэтому удалялись сильно коррелирующие столбцы именно с гиперпараметром.\n",
    "\n",
    "Удаляя эти столбцы, мы приводили матрицу корреляции к удовлетворяющему нас виду.\n",
    "\n",
    "Но, самая основная проблема и недостаток этого метода, заключается в том, что нет никакой информации о том, что гиперпараметр более важен для нас, чем составляющие его столбцы. Удаляя эти столбцы, мы можем потерять важный для нас признак даже не зная об этом.\n",
    "```\n",
    "\n",
    "- Исходя из анализа важности столбцов для моделей, в варианте решения №1, видно, что **топ параметов** как для модели Extreme Gradient Boosting, так и для моделей Random Forest и CatBoost **неизменен**. Это такие параметры как (**Разница стабильности, Степень износа, Дыхание Истока, Баланс угасания**). Значит, эти параметры очень важны для представленных моделей, и при отсутствии их, модели вероятнее всего, обучатся менее эффективно (как это и произошло).\n",
    "\n",
    "- При решении задачи методом №2, в процессе \"чистки данных\", касательно матрицы корреляции, были удалены такие столбцы как (**Разница стабильности, Дыхание Истока**). Это значит, что **были удалены** параметры по важности, входящие в **топ3** (ранее, в варианте решения №1, я написал, что 4 параметра обязательно должны быть в DataFrame, они вносят самый большой вклад в модель и в решение в целом. Решая вторым вариантом задачу, 2 самых важных параметра были удалены), хотя это было абсолютно не очевидно, казалось, что это обычные коррелирующие столбцы, собственно, как и все. Этот ход существенно повлиял на результаты.\n",
    "\n",
    "Все это говорит о том, что решая задачу методом №2, **трудно** обьективно **аргументировать** выбор, **что же удалять** между несколькими сильно коррелирующими столбцами. Мы можем **не угадать** и удалить **важный** признак.\n",
    "\n",
    "Решая задачу вариантом решения №1, мы можем абсолютно точно быть **уверены** в том, что никакие **важные** признаки **удалены не были**. Хоть матрица корреляции все-таки и получилась неудовлетворяющей нас, но чистить ее уже нет никакого смысла, ведь в нее входят все самые важные параметры.\n",
    "```\n",
    "```\n",
    "**Выбор лучшего решения:**\n",
    "\n",
    "```\n",
    "В качестве лучшего решения выбираю вариант №1 - необходимо удостовериться и быть полностью уверенным в том, что удаляемый признак может быть спокойно удален без дальнейшего ущерба.\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "**Выбор лучшей модели:**\n",
    "\n",
    "```\n",
    "В качестве лучшей модели выступил метод: Extreme Gradient Boosting.\n",
    "\n",
    "Он смог адаптироваться и быстро обучиться на большом наборе сильно коррелирующих столбцов. Показал лучший показатель score и минимальную метрику ошибки MAE. Хорошо показал себя на кросс-валидации, с высоким средедним значением R^2, с низкими значениями стандартного отклонения R^2, с низким среднем значением MAE и с низким стандартным отклонением MAE, что говорит о надежности данной модели. Так же XGBoost имеет лучшее распределение на Scatter Plot.\n",
    "\n",
    "В сочетании с решением №1, метод Extreme Gradient Boosting имеет показатели:\n",
    "```\n",
    "**- Score на тренировочных данных =  0.9995**\n",
    "\n",
    "**- Score на тестовых данных =  0.9993**\n",
    "\n",
    "**- MAE на тестовых данных = 0.0001**\n",
    "```\n",
    "При оценивании распределения точек на Scatter Plot, для данного метода, видно, что практически все точки лежат на диагональной прямой, что сведетельствует о совпадении истинных и предсказанных значений.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676fd394-ea3e-4638-ab2c-c272a75eb281",
   "metadata": {},
   "source": [
    "## Сложности при решении"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac3420-e3dd-40e7-b76f-0d0b1a6df0f3",
   "metadata": {},
   "source": [
    "- Основная сложность задачи была из-за высокой мультиколлинеарности между признаками. Необходимо было удалить множество столбцов, и аргументировать это, чтобы добиться допустимых значений корреляции. \n",
    "\n",
    "- Вызвали вопросы значения 'Исток не вернул выдох' и 'Древний Ветер развеялся'. Изначально было несовсем понятно, как интерпретировать их, и аргументировать перенос их к пропущенным значениям. Пришлось провести анализ этих явлений, выяснить что количество этих явлений одинаково между собой, что эти явления происходят строго параллельно, проанализировать, что это может быть в реальной жизни (т.к данная задача - это реальный кейс).\n",
    "\n",
    "- Вызвали сложности большое количество пропущенных значений в столбцах \"Температура вдоха Истока\" и \"Давление вдоха Истока\". Было непонятно что с ними делать, до момента построения корреляционный матрицы. Были мысли о замене их на средние и медианные значения.\n",
    "\n",
    "\n",
    "Пришлось додумать другой вариант решения (вариант решения №1). При удалении сильно коррелирующих столбцов были сомнения о правильности действий, ведь было удалено большое количество данных, которые на самом деле могут быть полезны.\n",
    "\n",
    "Были мысли о том, как бы не переобучить модель, когда показатели score равнялись 1. Как это получилось и с методом ближайших соседей. Было придумано, написасть цикл и прогнать модель несколько раз с разными значениями random_state, для тестирования модели на данных после перемешивания и так же использовать кросс-валидацию и оценить результаты на метриках ошибки."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
