<p align="center">
   <img src="Other/cxg1zjmnr497zeq15ne9zzlausjb6obw.png" width="600">
</p>
<p align="center">
   <img src="https://img.shields.io/badge/Language-Jupyter Notebook-orange">
</p>
<p align="center">
   <img src="https://img.shields.io/badge/DecisionTree-2bd000">
   <img src="https://img.shields.io/badge/Random Forest-1c17e7">
   <img src="https://img.shields.io/badge/KNeighbors-a0109c">
   <img src="https://img.shields.io/badge/LinearRegression-80fed2">
   <img src="https://img.shields.io/badge/XGBoost-dc3f16">
   <img src="https://img.shields.io/badge/CatBoost-ebe633">
</p>

## About
<p align="Left">
   Данный кейс представляет собой задачу регресии. Все столбцы и значения в данных закодированы в вымышленные.

   Необходимо предсказать целевую переменную - "Гармония бессмертия".
</p>

## Methods
   <p align="Left">
  <b>В процессе решения данного кейса были использованы методы ML:</b>
  
   <p align="Left">
   <p> 1. Extreme Gradient Boosting (XGBRegressor)</p>
   <p> 2. KNeighbors (KNeighborsRegressor)</p>
   <p> 3. Decision Tree (DecisionTreeRegressor)</p>
   <p>  4. Random Forest (RandomForestRegressor)</p>
   <p> 5. LinearRegression (LinearRegression)</p>
   <p> 6. CatBoost (CatBoostRegressor)</p>
   </p>
  <br>
  <b>Метрики качества и ошибки:</b>
  <p align="Left">
  <p>  1. Коэффициент детерминации (Score - R^2)</p>
  <p>  2. Mean absolute error (MAE)</p>
  </p>  
  <br>
  <b>Методы масштабирования данных:</b>
  <p align="Left">
  <p>  1. StandardScaler </p>
  <p>  2. RobustScaler </p>
  </p>  
  

## Best scores
<p align="Left">
   В качестве лучшей модели выступил метод: Extreme Gradient Boosting.
<p align="Left">
   <p> 1. Score на тренировочных данных = 0.9995</p>
   <p> 2. Score на тестовых данных = 0.9993</p>
   <p> 3. MAE на тестовых данных = 0.0001</p>
   </p>
</p>

## Sources
<p align="Left">
   Подробное описание задание прикреплено в файле: 

   Данные для решения в файле: 
</p>
